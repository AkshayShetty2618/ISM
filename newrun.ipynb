{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "newrun.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAEWMpt-vu3p",
        "outputId": "2bc00003-1e85-4116-a795-4a947334a294"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "j28Q1Jzzvv62",
        "outputId": "806575ba-03d9-4de6-c435-df63175beaf9"
      },
      "source": [
        "import pandas as pd\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from sklearn.svm import SVC\r\n",
        "from pathlib import Path\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from mpl_toolkits.mplot3d import Axes3D\r\n",
        "from matplotlib import cm\r\n",
        "from matplotlib.colors import hsv_to_rgb\r\n",
        "from numpy import asarray\r\n",
        "from keras.preprocessing.image import load_img\r\n",
        "\r\n",
        "class preprocessing:\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        self.train_data = pd.read_csv(r'/content/drive/MyDrive/groundtruth_train.csv', index_col=False)\r\n",
        "        self.im_path = '/content/drive/MyDrive/ISIC_2019_Training_Input/'\r\n",
        "        self.imageName_set = self.train_data['image']\r\n",
        "        self.train_data = self.train_data.drop(['image'], axis=1)\r\n",
        "        self.Y_labels = None\r\n",
        "        self.X_set = None\r\n",
        "        Y_labels = []\r\n",
        "        X_set = []\r\n",
        "        new_list = []\r\n",
        "        counter = 0\r\n",
        "        for i in range(self.imageName_set.shape[0]):\r\n",
        "            if self.imageName_set[i] != 'ATTRIBUTION.txt':\r\n",
        "                # image = cv2.imread(os.path.join(self.im_path, self.imageName_set[i] + '.jpg'))\r\n",
        "                image = cv2.imread(self.im_path + self.imageName_set[i] + '.jpg')\r\n",
        "\r\n",
        "                image_orig = cv2.resize(image, dsize=(700, 700))\r\n",
        "                image = self.apply_discmasking(image_orig)\r\n",
        "                image = self.apply_dullrazor(image)\r\n",
        "                image = self.median_filter(image)\r\n",
        "                image = self.apply_kmeans(image)\r\n",
        "                hsv, lab, enh = self.apply_AHE(image)\r\n",
        "                grab_img = self.grabcut_mask(image_orig, enh)\r\n",
        "                # cv2.imshow(\"Final\", grab_img)\r\n",
        "                # cv2.waitKey(0)\r\n",
        "                array_image = np.asarray(grab_img)\r\n",
        "                array_image.flatten()\r\n",
        "\r\n",
        "                img_array = array_image.reshape(-1, 1).T\r\n",
        "                new_list.append(img_array)\r\n",
        "\r\n",
        "                # so now i want to convert this to csv\r\n",
        "                ind_lab = self.train_data.iloc[i].values\r\n",
        "                Y_labels.append((np.where(ind_lab == 1))[0][0])\r\n",
        "                counter = counter + 1\r\n",
        "                if counter % 100 == 0:\r\n",
        "                    print(\"Total \" + str(counter) + \"/\" + str(self.imageName_set.shape[0] - 1) + \" images processed.!!\")\r\n",
        "\r\n",
        "        print(Y_labels)\r\n",
        "        x = np.asarray(new_list)\r\n",
        "        Y_labels = np.asarray(Y_labels)\r\n",
        "        X = pd.DataFrame(x)\r\n",
        "        self.X_set = X.to_csv(\"train_Data.csv\", index=False)\r\n",
        "        Y = pd.Series(Y_labels)\r\n",
        "        self.Y_labels = Y.to_csv(\"labels.csv\", index=False)\r\n",
        "\r\n",
        "    def read_csvs(self):\r\n",
        "        self.train_csv = pd.read_csv(self.csv_name)\r\n",
        "        self.test_csv = pd.read_csv(os.path.join(self.csv_path, \"groundtruth_val\"))\r\n",
        "\r\n",
        "    def convert_togray(self, image):\r\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n",
        "        return gray\r\n",
        "\r\n",
        "    def median_filter(self, image):\r\n",
        "        median = cv2.medianBlur(image, 5)\r\n",
        "        return median\r\n",
        "\r\n",
        "    def svm_classifier(self,train,lables):\r\n",
        "        SVC_classifier = SVC(C=10.0, gamma=0.05)\r\n",
        "        SVC_classifier.fit(train, lables)\r\n",
        "        #svc_preds = SVC_classifier.predict(scaled_test)\r\n",
        "\r\n",
        "    def apply_discmasking(self, image):\r\n",
        "        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n",
        "        r, g, b = cv2.split(img)\r\n",
        "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\r\n",
        "        h, s, v = cv2.split(hsv)\r\n",
        "\r\n",
        "        light_red = (0, 180, 180)\r\n",
        "        dark_red = (10, 250, 255)\r\n",
        "        light_orange = (10, 150, 200)\r\n",
        "        dark_orange = (18, 255, 255)\r\n",
        "        light_yellow = (18, 60, 140)\r\n",
        "        dark_yellow = (30, 250, 255)\r\n",
        "\r\n",
        "        light_green = (52, 75, 80)\r\n",
        "        dark_green = (80, 255, 255)\r\n",
        "\r\n",
        "        light_blue = (85, 50, 75)\r\n",
        "        dark_blue = (125, 250, 255)\r\n",
        "\r\n",
        "        light_ink = (105, 1, 50)\r\n",
        "        dark_ink = (175, 220, 255)\r\n",
        "\r\n",
        "        m = img.shape[0]\r\n",
        "        n = img.shape[1]\r\n",
        "        template = np.ones((m, n))\r\n",
        "        template = template.astype(int)\r\n",
        "\r\n",
        "        a = r.flatten()\r\n",
        "        counts = np.bincount(a)\r\n",
        "        r_max = np.argmax(counts)\r\n",
        "\r\n",
        "        a = g.flatten()\r\n",
        "        counts = np.bincount(a)\r\n",
        "        g_max = np.argmax(counts)\r\n",
        "\r\n",
        "        a = b.flatten()\r\n",
        "        counts = np.bincount(a)\r\n",
        "        b_max = np.argmax(counts)\r\n",
        "\r\n",
        "        rn = template * r_max\r\n",
        "        gn = template * g_max\r\n",
        "        bn = template * b_max\r\n",
        "        skin = np.dstack([rn, gn, bn])\r\n",
        "        \r\n",
        "        orange_mask = cv2.inRange(hsv, light_orange, dark_orange)\r\n",
        "        red_mask = cv2.inRange(hsv, light_red, dark_red)\r\n",
        "        yellow_mask = cv2.inRange(hsv, light_yellow, dark_yellow)\r\n",
        "        green_mask = cv2.inRange(hsv, light_green, dark_green)\r\n",
        "        blue_mask = cv2.inRange(hsv, light_blue, dark_blue)\r\n",
        "        ink_mask = cv2.inRange(hsv, light_ink, dark_ink)\r\n",
        "\r\n",
        "        # Creates a Black mask for the colored region\r\n",
        "        om = cv2.bitwise_not(orange_mask)\r\n",
        "        rm = cv2.bitwise_not(red_mask)\r\n",
        "        ym = cv2.bitwise_not(yellow_mask)\r\n",
        "        gm = cv2.bitwise_not(green_mask)\r\n",
        "        bm = cv2.bitwise_not(blue_mask)\r\n",
        "        im = cv2.bitwise_not(ink_mask)\r\n",
        "\r\n",
        "        # Extracts a SkinPatch in the color pattern\r\n",
        "        skinPatch = cv2.bitwise_and(skin, skin, mask=orange_mask)\r\n",
        "        spr = cv2.bitwise_and(skin, skin, mask=red_mask)\r\n",
        "        spy = cv2.bitwise_and(skin, skin, mask=yellow_mask)\r\n",
        "        spg = cv2.bitwise_and(skin, skin, mask=green_mask)\r\n",
        "        spb = cv2.bitwise_and(skin, skin, mask=blue_mask)\r\n",
        "        spi = cv2.bitwise_and(skin, skin, mask=ink_mask)\r\n",
        "\r\n",
        "        # replaces the Color pixel with black and then with the skin color\r\n",
        "        imnew = cv2.bitwise_and(img, img, mask=om)\r\n",
        "        rst = cv2.add(imnew, skinPatch, dtype=cv2.CV_8UC1)\r\n",
        "\r\n",
        "        rst = cv2.bitwise_and(rst, rst, mask=rm)\r\n",
        "        rst = cv2.add(rst, spr, dtype=cv2.CV_8UC1)\r\n",
        "\r\n",
        "        rst = cv2.bitwise_and(rst, rst, mask=ym)\r\n",
        "        rst = cv2.add(rst, spy, dtype=cv2.CV_8UC1)\r\n",
        "\r\n",
        "        rst = cv2.bitwise_and(rst, rst, mask=gm)\r\n",
        "        rst = cv2.add(rst, spg, dtype=cv2.CV_8UC1)\r\n",
        "\r\n",
        "        rst = cv2.bitwise_and(rst, rst, mask=bm)\r\n",
        "        rst = cv2.add(rst, spb, dtype=cv2.CV_8UC1)\r\n",
        "\r\n",
        "        rst = cv2.bitwise_and(rst, rst, mask=im)\r\n",
        "        rst = cv2.add(rst, spi, dtype=cv2.CV_8UC1)\r\n",
        "\r\n",
        "        rst = rst.astype(np.uint8)\r\n",
        "\r\n",
        "        return rst\r\n",
        "\r\n",
        "    def apply_dullrazor(self, image):\r\n",
        "        grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\r\n",
        "        kernel = cv2.getStructuringElement(1, (17, 17))\r\n",
        "        blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\r\n",
        "\r\n",
        "        ret, thresh2 = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\r\n",
        "        thresh3 = cv2.adaptiveThreshold(blackhat, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11,\r\n",
        "                                        2)  # Adaptive gaussian\r\n",
        "        thresh4 = cv2.adaptiveThreshold(blackhat, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11,\r\n",
        "                                        2)  # Adaptive gaussian\r\n",
        "\r\n",
        "        # inpaint the original image depending on the mask\r\n",
        "        dst = cv2.inpaint(image, thresh2, 10, cv2.INPAINT_TELEA)\r\n",
        "\r\n",
        "        return dst\r\n",
        "\r\n",
        "    def apply_kmeans(self, image):\r\n",
        "\r\n",
        "        Z = image.reshape((-1, 3))\r\n",
        "        Z = np.float32(Z)\r\n",
        "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\r\n",
        "        K = 15\r\n",
        "        ret, label, center = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\r\n",
        "\r\n",
        "        center = np.uint8(center)\r\n",
        "        res = center[label.flatten()]\r\n",
        "        kmeans_img = res.reshape((image.shape))\r\n",
        "        # cv2.imshow(\"Kmeans img\", kmeans_img)\r\n",
        "        # cv2.waitKey(0)\r\n",
        "        return kmeans_img\r\n",
        "\r\n",
        "    def apply_AHE(self, image):\r\n",
        "        clahe = cv2.createCLAHE(clipLimit=3., tileGridSize=(8,8))\r\n",
        "\r\n",
        "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\r\n",
        "        h, s, v = cv2.split(hsv)\r\n",
        "\r\n",
        "        h1 = clahe.apply(h)\r\n",
        "        s1 = clahe.apply(s)\r\n",
        "        v1 = clahe.apply(v)\r\n",
        "\r\n",
        "        lab = cv2.merge((h1, s1, v1))\r\n",
        "        \r\n",
        "        enhanced_img = cv2.cvtColor(lab, cv2.COLOR_Lab2BGR)\r\n",
        "        \r\n",
        "        return hsv, lab, enhanced_img\r\n",
        "\r\n",
        "    def grabcut_mask(self, image, enhancedimg):\r\n",
        "        hsv_img = cv2.cvtColor(enhancedimg, cv2.COLOR_BGR2HSV)\r\n",
        "\r\n",
        "        lower_green = np.array([50,100,100])\r\n",
        "        higher_green = np.array([100,255,255])\r\n",
        "        mask = cv2.inRange(hsv_img, lower_green, higher_green)\r\n",
        "\r\n",
        "        ret, inv_mask = cv2.threshold(mask, 200, 255, cv2.THRESH_BINARY_INV)\r\n",
        "\r\n",
        "        res = cv2.bitwise_and(image, image, mask=mask)\r\n",
        "\r\n",
        "        new_mask = np.zeros(image.shape[:2], np.uint8)\r\n",
        "        bgdModel = np.zeros((1, 65), np.float64)\r\n",
        "        fgdModel = np.zeros((1, 65), np.float64)\r\n",
        "\r\n",
        "        if (np.sum(inv_mask[:]) < 80039400):\r\n",
        "            newmask = inv_mask\r\n",
        "            new_mask[newmask == 0] = 0\r\n",
        "            new_mask[newmask == 255] = 1\r\n",
        "            dim = cv2.grabCut(image, new_mask, None, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)\r\n",
        "            mask2 = np.where((new_mask == 2) | (new_mask == 0), 0, 1).astype('uint8')\r\n",
        "            GrabCut_img = image * mask2[:, :, np.newaxis]\r\n",
        "            #cv2.imshow(\"Grab img\", GrabCut_img)\r\n",
        "            #cv2.waitKey(0)\r\n",
        "\r\n",
        "        else:\r\n",
        "            s = (int(image.shape[0] / 10), int(image.shape[1] / 10))\r\n",
        "            rect = (s[0], s[1], int(image.shape[0] - (3 / 10) * s[0]), image.shape[1] - s[1])\r\n",
        "            cv2.grabCut(enhancedimg, new_mask, rect, bgdModel, fgdModel, 10, cv2.GC_INIT_WITH_RECT)\r\n",
        "            mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\r\n",
        "            GrabCut_img = image * mask2[:, :, np.newaxis]\r\n",
        "            #cv2.imshow(\"Grab img\", GrabCut_img)\r\n",
        "            #cv2.waitKey(0)\r\n",
        "\r\n",
        "        imgmask = cv2.medianBlur(GrabCut_img, 5)\r\n",
        "        ret, Segmented_mask = cv2.threshold(imgmask, 0, 255, cv2.THRESH_BINARY)\r\n",
        "\r\n",
        "        if (np.sum(inv_mask[:]) < 80039400):\r\n",
        "            newmask = inv_mask\r\n",
        "            new_mask[newmask == 0] = 0\r\n",
        "            new_mask[newmask == 255] = 1\r\n",
        "            dim = cv2.grabCut(image, new_mask, None, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)\r\n",
        "            mask2 = np.where((new_mask == 2) | (new_mask == 0), 0, 1).astype('uint8')\r\n",
        "            GrabCut_img2 = image * mask2[:, :, np.newaxis]\r\n",
        "            #cv2.imshow(\"Grab img\", GrabCut_img)\r\n",
        "            #cv2.waitKey(0)\r\n",
        "\r\n",
        "        else:\r\n",
        "            s = (int(image.shape[0] / 10), int(image.shape[1] / 10))\r\n",
        "            rect = (s[0], s[1], int(image.shape[0] - (3 / 10) * s[0]), image.shape[1] - s[1])\r\n",
        "            cv2.grabCut(enhancedimg, new_mask, rect, bgdModel, fgdModel, 10, cv2.GC_INIT_WITH_RECT)\r\n",
        "            mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\r\n",
        "            GrabCut_img2 = image * mask2[:, :, np.newaxis]\r\n",
        "            #cv2.imshow(\"Grab img\", GrabCut_img)\r\n",
        "            #cv2.waitKey(0)\r\n",
        "\r\n",
        "        imgmask2 = cv2.medianBlur(GrabCut_img2, 5)\r\n",
        "        ret, Segmented_mask2 = cv2.threshold(imgmask2, 0, 255, cv2.THRESH_BINARY)\r\n",
        "\r\n",
        "        return GrabCut_img2\r\n",
        "        # return Segmented_mask2\r\n",
        "    \r\n",
        "if __name__ == '__main__':\r\n",
        "    pre = preprocessing()\r\n",
        "    X_train = pre.X_set\r\n",
        "    Y_train = pre.Y_labels\r\n",
        "    pre.svm_classifier(X_train, Y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-26ede0ca02ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-26ede0ca02ce>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_kmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mhsv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_AHE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mgrab_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrabcut_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;31m# cv2.imshow(\"Final\", grab_img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;31m# cv2.waitKey(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-26ede0ca02ce>\u001b[0m in \u001b[0;36mgrabcut_mask\u001b[0;34m(self, image, enhancedimg)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mnew_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mnew_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrabCut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgdModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgdModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGC_INIT_WITH_MASK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0mmask2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_mask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mGrabCut_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/grabcut.cpp:386: error: (-215:Assertion failed) !bgdSamples.empty() && !fgdSamples.empty() in function 'initGMMs'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0r3aM7oxNDA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}